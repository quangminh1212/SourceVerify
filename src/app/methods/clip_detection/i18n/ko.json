{
    "useCase": "",
    "mechanism": "",
    "accuracy": "",
    "name": "CLIP-based AI Detection",
    "source": "",
    "algorithm": "CLIP ViT-L/14 + Linear Probe Classifier",
    "parameters": "",
    "description": "Leverages OpenAI CLIP vision-language model to detect semantic inconsistencies between image content and expected real-world properties. Uses contrastive learning for zero-shot detection.",
    "references": [
        {
            "title": "Radford, A. et al. (2021). Learning Transferable Visual Models From Natural Language Supervision. ICML.",
            "url": "https://arxiv.org/abs/2103.00020"
        },
        {
            "title": "Ojha, U. et al. (2023). Towards Universal Fake Image Detectors that Generalize Across Generative Models. CVPR.",
            "url": "https://arxiv.org/abs/2302.10174"
        }
    ]
}
