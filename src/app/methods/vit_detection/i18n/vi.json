{
    "useCase": "Phát hiện nội dung AI sử dụng mẫu chú ý toàn cục nắm bắt hiện vật cục bộ và tầm xa",
    "mechanism": "Chia ảnh thành các mảnh 16x16 và xử lý qua bộ mã hóa Vision Transformer với cơ chế tự chú ý đa đầu. Cơ chế chú ý nắm bắt phụ thuộc tầm xa và mẫu toàn cục trên toàn ảnh. Đầu ra token [CLS] đưa vào đầu phân loại để xác định thật/AI.",
    "accuracy": "Cao - 88-94% với tổng quát hóa tốt giữa các bộ tạo",
    "name": "Phát hiện bằng Vision Transformer (ViT)",
    "source": "Dosovitskiy et al. (2021) - Một ảnh đáng giá 16x16 từ, ICLR; ứng dụng pháp y bởi Cocchi et al. (2023)",
    "algorithm": "ViT-Base/16 + Phân tích bản đồ attention",
    "parameters": "Kích thước mảnh: 16x16, Chiều ẩn: 768, Đầu chú ý: 12, Tầng: 12, Đầu vào: 224x224, Phân loại: đầu MLP trên token [CLS]",
    "description": "Sử dụng kiến trúc Vision Transformer để nắm bắt phụ thuộc tầm xa trong ảnh. ViT vượt trội phát hiện mẫu toàn cục tinh tế mà CNN có thể bỏ sót.",
    "strengths": "• Nắm bắt ngữ cảnh ảnh toàn cục qua tự chú ý\n• Tổng quát hóa xuất sắc giữa các bộ tạo\n• Bản đồ chú ý cung cấp khả năng giải thích\n• Mở rộng tốt với tập dữ liệu lớn hơn",
    "limitations": "• Yêu cầu tài nguyên tính toán đáng kể\n• Kích thước mô hình lớn và chiếm nhiều bộ nhớ\n• Cần tập dữ liệu huấn luyện lớn cho hiệu suất tối ưu\n• Phương pháp dựa trên mảnh có thể bỏ sót hiện vật dưới mảnh",
    "references": [
        {
            "title": "Dosovitskiy, A. et al. (2021). An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale. ICLR.",
            "url": "https://arxiv.org/abs/2010.11929"
        },
        {
            "title": "Cocchi, F. et al. (2023). Unveiling the Impact of Image Transformations on Deepfake Detection. Image and Vision Computing.",
            "url": "https://doi.org/10.1016/j.imavis.2023.104811"
        }
    ]
}
